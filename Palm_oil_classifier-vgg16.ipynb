{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oil Palm Satellite imaging\n",
    "\n",
    "Oil palm has become a means of rapid agricultural growth in tropical areas where it thrives. This resource can be found in products ranging from shampoo to frozen foods. While increasing job availabilities, oil palm plantations have led to a dramatic rise in deforestation and loss of biodiversity. Species like the Orangutan and Sumatran Tiger are being displaced from their lands and pushed closer to extinction.\n",
    "\n",
    "The objective here is to use high-resolution satellite imaging to automate mapping of oil palm plantations and track this rising and alarming trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4zIaa5Bclws"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1226,
     "status": "ok",
     "timestamp": 1550963852584,
     "user": {
      "displayName": "Will Morgan",
      "photoUrl": "",
      "userId": "05845904692204085913"
     },
     "user_tz": 480
    },
    "id": "SZFddCLav73O",
    "outputId": "8ed71b2b-55fc-49c6-8f0b-e33c1ce968a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: training on GPU\n"
     ]
    }
   ],
   "source": [
    "# check if GPU available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if train_on_gpu:\n",
    "    print(\"CUDA available: training on GPU\")\n",
    "else:\n",
    "    print(\"CUDA unavailable: training on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQA-YsbweFFf"
   },
   "outputs": [],
   "source": [
    "# set image locations\n",
    "train_image_dir = 'data/palm_train/'\n",
    "test_image_dir = 'data/leaderboard_test_data/'\n",
    "holdout_image_dir = 'data/leaderboard_holdout_data/'\n",
    "has_palm_dir = 'data/palm_train/palm/palm/'\n",
    "no_palm_dir = 'data/palm_train/no_palm/no_palm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1550963834152,
     "user": {
      "displayName": "Will Morgan",
      "photoUrl": "",
      "userId": "05845904692204085913"
     },
     "user_tz": 480
    },
    "id": "n8lq2U5GfG3z",
    "outputId": "8b95e5c6-fff3-4151-adaf-f54b1ef94735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images with palm oil plantations:  936\n",
      "Number of images without palm oil plantations:  14302\n"
     ]
    }
   ],
   "source": [
    "# list the class sizes\n",
    "print(\"Number of images with palm oil plantations: \", len(os.listdir(has_palm_dir)))\n",
    "print(\"Number of images without palm oil plantations: \", len(os.listdir(no_palm_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-PtChr3g9nF"
   },
   "source": [
    "#### Class imbalance\n",
    "Neural networks are known to be good at handling class imbalances. Nevertheless, it's worthwhile to consider this an issue and attempt to minimize. Some options include: \n",
    "\n",
    "\n",
    "- undersampling majority class in training \n",
    "\n",
    "- creating more minority class images by manipulating original images \n",
    "\n",
    "- Built in Pytorch weighted classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and transform data\n",
    "Here I will add random transformations to the labeled dataset to prevent overfitting of the model. I also normalize all images to the attributes of the ImageNet data that our models are pre-trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2866,
     "status": "error",
     "timestamp": 1550963858518,
     "user": {
      "displayName": "Will Morgan",
      "photoUrl": "",
      "userId": "05845904692204085913"
     },
     "user_tz": 480
    },
    "id": "6GpA5P6SiVkL",
    "outputId": "5aa8bbb1-7201-41b1-ac69-2938bce4474a"
   },
   "outputs": [],
   "source": [
    "# set data transforms\n",
    "train_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),\n",
    "                                      transforms.RandomRotation([-30,30]),\n",
    "                                      transforms.ColorJitter(brightness=0.5, contrast=0.75),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                     ])\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                     ])\n",
    "\n",
    "# load data with ImageFolder\n",
    "train_dataset = datasets.ImageFolder(train_image_dir, transform=train_transform)\n",
    "\n",
    "holdout_dataset = datasets.ImageFolder(holdout_image_dir, transform=transform)\n",
    "\n",
    "# competition test dataset, not to be confused with the 'test' set extracted from the training data\n",
    "comp_test_dataset = datasets.ImageFolder(test_image_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See link for representations of transformations above: \n",
    "\n",
    "https://colab.research.google.com/drive/109vu3F1LTzD1gdVV6cho9fKGx7lzbFll#scrollTo=BM7-0e4pzLXN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2eFK7nwtmnE"
   },
   "outputs": [],
   "source": [
    "# create validation and test subsets from the training data\n",
    "valid_size=0.2\n",
    "\n",
    "# for optimizing purposes, I'll keep the group splits consistent\n",
    "np.random.seed(2)\n",
    "\n",
    "# split training and validation set\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# split a testing group out of validation set\n",
    "valid_size = 0.5 # 10% validation, 10% test\n",
    "num_valid = len(valid_idx)\n",
    "new_split = int(np.floor(split * 0.5))\n",
    "valid_idx, test_idx = valid_idx[:new_split], valid_idx[new_split:]\n",
    "\n",
    "# define subset sampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4tGQ5_Mv6aJ"
   },
   "outputs": [],
   "source": [
    "# defining parameters for dataloader\n",
    "num_workers = 0\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1550944319375,
     "user": {
      "displayName": "Cindy Barrientos",
      "photoUrl": "",
      "userId": "12086480283447792262"
     },
     "user_tz": 480
    },
    "id": "vFJiNwoHwhwF",
    "outputId": "460162ae-c5fe-4911-f5af-c1c89833c33c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices length: 12191\n",
      "Validation indices length: 1523\n",
      "Test indices length: 1524 \n"
     ]
    }
   ],
   "source": [
    "print (\"Train indices length: {}\\nValidation indices length: {}\\nTest indices length: {} \".format(\n",
    "    len(train_idx), len(valid_idx), len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_8rD1JTDw4lN"
   },
   "outputs": [],
   "source": [
    "# prepare data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find class distributions post- train/val/test split\n",
    "Here I ensure that there is a fairly even split of minority images between the groupings (roughly 6-7% each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution of training set:\n",
      "(array([0, 1], dtype=int64), array([11450,   741], dtype=int64))\n",
      "\n",
      "Class distribution of validation set:\n",
      "(array([0, 1], dtype=int64), array([1413,  110], dtype=int64))\n",
      "\n",
      "Class distribution of test set:\n",
      "(array([0, 1], dtype=int64), array([1439,   85], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# find class distribution\n",
    "\n",
    "train_dist = []\n",
    "\n",
    "for img, labels in train_loader:\n",
    "    train_dist.extend(labels)\n",
    "\n",
    "print('Class distribution of training set:')   \n",
    "x=torch.stack(train_dist).numpy()\n",
    "print(np.unique(x, return_counts=True))\n",
    "\n",
    "\n",
    "valid_dist = []\n",
    "\n",
    "for img, labels in valid_loader:\n",
    "    valid_dist.extend(labels)\n",
    "\n",
    "print('\\nClass distribution of validation set:')\n",
    "x=torch.stack(valid_dist).numpy()\n",
    "print(np.unique(x, return_counts=True))\n",
    "\n",
    "\n",
    "test_dist = []\n",
    "\n",
    "for img, labels in test_loader:\n",
    "    test_dist.extend(labels)\n",
    "\n",
    "print('\\nClass distribution of test set:')\n",
    "x=torch.stack(test_dist).numpy()\n",
    "print(np.unique(x, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18831,
     "status": "ok",
     "timestamp": 1550944343337,
     "user": {
      "displayName": "Cindy Barrientos",
      "photoUrl": "",
      "userId": "12086480283447792262"
     },
     "user_tz": 480
    },
    "id": "sT-KNkM02ZYO",
    "outputId": "496e0a94-7558-445e-a4ae-7982fe3df0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define our model\n",
    "model = models.vgg16(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4fgaI22vw8a0"
   },
   "source": [
    "### Set model parameters\n",
    "Will set criterion and optimizer, as well as modify classifier layers to fit the class structure of our dataset. For example, ImageNet has 1000 classes to differentiate, here we only have 2 (true or false for palm oil plantation presence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkuKJ46W15tc"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1410,
     "status": "ok",
     "timestamp": 1550947526214,
     "user": {
      "displayName": "Cindy Barrientos",
      "photoUrl": "",
      "userId": "12086480283447792262"
     },
     "user_tz": 480
    },
    "id": "IDVJozDa4jdU",
    "outputId": "ee03f599-4a83-4eae-a3a7-06847933b885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.25)\n",
      "    (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (relu2): ReLU()\n",
      "    (dropout2): Dropout(p=0.25)\n",
      "    (output): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# freeze the features layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(25088, 4096)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('dropout1', nn.Dropout(p=0.25)),\n",
    "    ('fc2', nn.Linear(4096, 4096)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('dropout2', nn.Dropout(p=0.25)),\n",
    "    ('output', nn.Linear(4096, 2))\n",
    "]))\n",
    "\n",
    "model.classifier = classifier\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we can verify which parameters are unfrozen and trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.fc1.weight\n",
      "\t classifier.fc1.bias\n",
      "\t classifier.fc2.weight\n",
      "\t classifier.fc2.bias\n",
      "\t classifier.output.weight\n",
      "\t classifier.output.bias\n"
     ]
    }
   ],
   "source": [
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fun part: training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 963
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32469,
     "status": "error",
     "timestamp": 1550947518680,
     "user": {
      "displayName": "Cindy Barrientos",
      "photoUrl": "",
      "userId": "12086480283447792262"
     },
     "user_tz": 480
    },
    "id": "GEWKvlMOqTes",
    "outputId": "2616c749-82c8-4fdb-d1e7-38c864d9d1a7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "\n",
      "\n",
      "Training/Validation time:   4.534853 minutes\n",
      "\n",
      "Epoch: 1 \tTraining Loss: 0.028295, Train Accuracy (Overall): 98.917234\n",
      "Epoch: 1 \tValidation Loss: 0.006298, Validation Accuracy (Overall): 98.227183\n",
      "Validation loss decreased (inf --> 0.006298). Saving model.\n",
      "Epoch:  2\n",
      "\n",
      "\n",
      "Training/Validation time:   9.145996 minutes\n",
      "\n",
      "Epoch: 2 \tTraining Loss: 0.024783, Train Accuracy (Overall): 98.917234\n",
      "Epoch: 2 \tValidation Loss: 0.004638, Validation Accuracy (Overall): 98.424163\n",
      "Validation loss decreased (0.006298 --> 0.004638). Saving model.\n",
      "Epoch:  3\n",
      "\n",
      "\n",
      "Training/Validation time:  13.821759 minutes\n",
      "\n",
      "Epoch: 3 \tTraining Loss: 0.026440, Train Accuracy (Overall): 98.974653\n",
      "Epoch: 3 \tValidation Loss: 0.005161, Validation Accuracy (Overall): 98.292843\n",
      "Epoch:  4\n",
      "\n",
      "\n",
      "Training/Validation time:  18.281534 minutes\n",
      "\n",
      "Epoch: 4 \tTraining Loss: 0.024008, Train Accuracy (Overall): 99.040276\n",
      "Epoch: 4 \tValidation Loss: 0.004782, Validation Accuracy (Overall): 98.489823\n",
      "Epoch:  5\n",
      "\n",
      "\n",
      "Training/Validation time:  22.741825 minutes\n",
      "\n",
      "Epoch: 5 \tTraining Loss: 0.025649, Train Accuracy (Overall): 98.933640\n",
      "Epoch: 5 \tValidation Loss: 0.004408, Validation Accuracy (Overall): 98.555483\n",
      "Validation loss decreased (0.004638 --> 0.004408). Saving model.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# move model to cuda\n",
    "if train_on_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "# defining parameters for model training\n",
    "n_epochs = 5\n",
    "valid_loss_min = np.Inf # track changes in validation loss\n",
    "\n",
    "# track losses over epochs\n",
    "ep_train_loss = []\n",
    "ep_valid_loss = []\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    print(\"Epoch: \", epoch)\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    num_classes = 2\n",
    "    # Calculating the number of correct predictions by the model in each class for training\n",
    "    train_class_correct = list(0. for i in range(num_classes))\n",
    "    # Calculate the total occurances of said class in the training set \n",
    "    train_class_total = list(0. for i in range(num_classes))\n",
    "        \n",
    "    # Calculating the number of correct predictions by the model in each class in validation\n",
    "    val_class_correct = list(0. for i in range(num_classes))\n",
    "    # Calculate the total occurances of said class in the validation set \n",
    "    val_class_total = list(0. for i in range(num_classes))\n",
    "    \n",
    "    \n",
    "  ##### train the model #####\n",
    "    model.train()\n",
    "  \n",
    "    for data, target in train_loader:\n",
    "        # move tensors to GPU if CUDA available\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # for each pass, clear the gradients of optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: pass inputs into the model\n",
    "        output = model(data)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct_tensor = preds.eq(target.data.view_as(preds))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        # calculate batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss\n",
    "        loss.backward()\n",
    "        # perform single optimization step, a parameter update\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(len(target.data)):\n",
    "            label = target.data[i]\n",
    "            train_class_correct[label] += correct[i].item()\n",
    "            train_class_total[label] += 1\n",
    "    \n",
    "    # track training time\n",
    "    #print('\\n\\nTraining time: {:10f} minutes'.format((time.time()-start_time)/60))\n",
    "    \n",
    "    \n",
    "  ##### validate the model #####\n",
    "    model.eval() # eliminates dropout\n",
    "    for data, target in valid_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        # compare predictions to true label\n",
    "        correct_tensor = preds.eq(target.data.view_as(preds))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        # calculate batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # update validation loss\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        for i in range(len(target.data)):\n",
    "            label = target.data[i]\n",
    "            val_class_correct[label] += correct[i].item()\n",
    "            val_class_total[label] += 1\n",
    "                \n",
    "                \n",
    "    # track training time\n",
    "    print('\\n\\nTraining/Validation time: {:10f} minutes\\n'.format((time.time()-start_time)/60))\n",
    "    \n",
    "    # calculate average losses\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "    ep_train_loss.append(train_loss)\n",
    "    ep_valid_loss.append(valid_loss)\n",
    "    \n",
    "    # print training/validation stats\n",
    "    #print('Epoch {} \\t Training Loss: {:.6f} \\t Validation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "\n",
    "    # print training statistics \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}, Train Accuracy (Overall): {:.6f}'.format(epoch, train_loss, (100. * np.sum(train_class_correct) / np.sum(train_class_total))))\n",
    "    # print validation statistics \n",
    "    print('Epoch: {} \\tValidation Loss: {:.6f}, Validation Accuracy (Overall): {:.6f}'.format(epoch, valid_loss, (100. * np.sum(val_class_correct) / np.sum(val_class_total))))\n",
    "\n",
    "    # save model if validation loss has decreased\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model.'.format(valid_loss_min, valid_loss))\n",
    "        torch.save(model.state_dict(), 'models/vgg16-clrjitr-5ep-sgd01.pt')\n",
    "        valid_loss_min = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1212,
     "status": "ok",
     "timestamp": 1550947550882,
     "user": {
      "displayName": "Cindy Barrientos",
      "photoUrl": "",
      "userId": "12086480283447792262"
     },
     "user_tz": 480
    },
    "id": "oPGzpx502-bA",
    "outputId": "bbe19641-1005-458d-e8cc-99c195c0f7e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (dropout1): Dropout(p=0.25)\n",
       "    (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (dropout2): Dropout(p=0.25)\n",
       "    (output): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### run this cell if returning to this project to skip training cell above\n",
    "model.load_state_dict(torch.load('models/vgg16-5ximg-5ep-sgd01.pt'))\n",
    "\n",
    "# double check this is the model we want to load\n",
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy (Overall): 98.81889763779527 (1506.0/1524.0)\n"
     ]
    }
   ],
   "source": [
    "## compare model with test subset accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0.0 for i in range(2)) # range of classes\n",
    "class_total = list(0.0 for i in range(2))\n",
    "target_list = []\n",
    "preds_list = []\n",
    "model.eval()\n",
    "model.cuda()\n",
    "def test_accuracy_check(model):\n",
    "    class_correct = list(0.0 for i in range(2)) # range of classes\n",
    "    class_total = list(0.0 for i in range(2))\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        if train_on_gpu:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        # get output to binary, max()\n",
    "        _, preds = torch.max(output, 1)\n",
    "        loss = criterion(output, target)\n",
    "        preds_list.append(preds)\n",
    "        target_list.append(target)\n",
    "        # compare preds to true label\n",
    "        correct = np.squeeze(preds.eq(target.data.view_as(preds)))\n",
    "        # calculate test accuracy for each class\n",
    "        for i in range(list(target.data.size())[0]):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "    return class_correct, class_total, preds_list, data, target_list, target\n",
    "\n",
    "class_correct, class_total, preds_list, data, target_list, target = test_accuracy_check(model)        \n",
    "        \n",
    "# compare to labels csv, get accuracy %\n",
    "print('\\nTest Accuracy (Overall): {} ({}/{})'.format(100.0000 * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = torch.cat(target_list).cpu().numpy()\n",
    "preds_list = torch.cat(preds_list).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1434,    5],\n",
       "       [  13,   72]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(target_list, preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(target_list, preds_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1439\n",
      "           1       0.94      0.85      0.89        85\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1524\n",
      "   macro avg       0.96      0.92      0.94      1524\n",
      "weighted avg       0.99      0.99      0.99      1524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(target_list, preds_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in test sets and create predictions\n",
    "\n",
    "I have both a test set and holdout set that is blind; instead of combining the data, I'll run them sequentially and add predictions to a dataframe for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_loader = torch.utils.data.DataLoader(holdout_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "comp_test_loader = torch.utils.data.DataLoader(comp_test_dataset, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### predict holdout set #####\n",
    "model.cuda()\n",
    "model.eval() # eliminates dropout\n",
    "preds = []\n",
    "for data, target in holdout_loader:\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    preds.extend(output)\n",
    "preds = torch.stack(preds)\n",
    "holdout_preds = torch.exp(F.log_softmax(preds.cpu(), dim=1))\n",
    "_, holdout_preds = torch.max(holdout_preds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_probs = torch.exp(F.log_softmax(preds.cpu(), dim=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### predict competition test set #####\n",
    "model.cuda()\n",
    "model.eval() # eliminates dropout\n",
    "comp_preds = []\n",
    "for data, target in comp_test_loader:\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    comp_preds.extend(output)\n",
    "comp_preds = torch.stack(comp_preds)\n",
    "comp_test_preds = torch.exp(F.log_softmax(comp_preds.cpu(), dim=1))\n",
    "_, comp_test_preds = torch.max(comp_test_preds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_test_probs = torch.exp(F.log_softmax(comp_preds.cpu(), dim=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get fileids into list\n",
    "holdout_fileid = os.listdir(holdout_image_dir + '1')\n",
    "comp_test_fileid = os.listdir(test_image_dir + '1')\n",
    "fileids = []\n",
    "fileids.extend(holdout_fileid)\n",
    "fileids.extend(comp_test_fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions into list\n",
    "has_oilpalm = []\n",
    "has_oilpalm.extend(holdout_probs.detach().numpy())\n",
    "has_oilpalm.extend(comp_test_probs.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare submission file for storing predictions\n",
    "import pandas as pd\n",
    "submission = pd.DataFrame(columns=['image_id', 'has_oilpalm'])\n",
    "submission['image_id'] = fileids\n",
    "submission['has_oilpalm'] = has_oilpalm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_oilpalm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.180968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.350614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.003228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.006934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.052189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.998857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       has_oilpalm\n",
       "count  6534.000000\n",
       "mean      0.180968\n",
       "std       0.350614\n",
       "min       0.000369\n",
       "25%       0.003228\n",
       "50%       0.006934\n",
       "75%       0.052189\n",
       "max       0.998857"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('subs/vgg16-5ximg-5ep-sgd01.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "WiDS_palm_oil_CB-vgg16.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
